package com.ai.reviewer.backend.domain.orchestrator.reviewer;

import com.ai.reviewer.backend.domain.config.AiReviewConfig;
import com.ai.reviewer.backend.domain.orchestrator.analyzer.StaticAnalyzer;
import com.ai.reviewer.shared.enums.Dimension;
import com.ai.reviewer.shared.enums.Severity;
import com.ai.reviewer.shared.model.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Component;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.CompletableFuture;

/**
 * Mock implementation of AiReviewer for testing and development.
 * 
 * <p>This mock reviewer returns predefined AI-style findings to demonstrate
 * the review workflow without requiring actual LLM API calls.
 */
@Component
public class MockAiReviewer implements AiReviewer {
    
    private static final Logger logger = LoggerFactory.getLogger(MockAiReviewer.class);
    
    @Override
    public String getReviewerId() {
        return "mock-ai-reviewer";
    }
    
    @Override
    public String getReviewerName() {
        return "Mock AI Reviewer";
    }
    
    @Override
    public String getModelVersion() {
        return "mock-gpt-4o";
    }
    
    @Override
    public boolean supportsLanguage(String language) {
        // Support common programming languages
        return List.of("java", "javascript", "typescript", "python", "go", "cpp", "c", "csharp")
                .contains(language.toLowerCase());
    }
    
    @Override
    public boolean isEnabled() {
        return true;
    }
    
    @Override
    public List<Finding> review(RepoRef repository, PullRef pullRequest, 
                              List<DiffHunk> diffHunks, AiReviewConfig config) {
        logger.info("Mock AI reviewer analyzing {} diff hunks for PR {}/{}#{}", 
            diffHunks.size(), repository.owner(), repository.name(), pullRequest.number());
        
        List<Finding> findings = new ArrayList<>();
        
        if (diffHunks.isEmpty()) {
            return findings;
        }
        
        // Generate mock AI-style findings based on the first diff hunk
        DiffHunk firstHunk = diffHunks.get(0);
        
        // Mock AI architecture/design finding
        findings.add(new Finding(
            "MOCK-AI-001",
            firstHunk.file(),
            3, 7,
            Severity.MINOR,
            Dimension.MAINTAINABILITY,
            "Consider using dependency injection pattern",
            "Direct instantiation of dependencies detected",
            "Consider using dependency injection to improve testability and maintainability. " +
            "This will make the code more modular and easier to test with mock objects.",
            null,
            List.of("mock-ai-reviewer"),
            0.78
        ));
        
        // Mock AI performance suggestion (only for larger changes)
        if (diffHunks.size() > 1 || countAddedLines(firstHunk) > 5) {
            findings.add(new Finding(
                "MOCK-AI-002",
                firstHunk.file(),
                10, 13,
                Severity.INFO,
                Dimension.PERFORMANCE,
                "Potential optimization opportunity",
                "Loop over large collection without early termination",
                "Consider adding early termination conditions or using parallel processing " +
                "for better performance when dealing with large datasets.",
                null,
                List.of("mock-ai-reviewer"),
                0.65
            ));
        }
        
        // Filter findings based on confidence threshold from config
        double confidenceThreshold = config.scoring().ignoreConfidenceBelow();
        List<Finding> filteredFindings = findings.stream()
            .filter(finding -> finding.confidence() >= confidenceThreshold)
            .toList();
        
        logger.info("Mock AI reviewer found {} findings (filtered from {} based on confidence threshold {})", 
            filteredFindings.size(), findings.size(), confidenceThreshold);
        
        return filteredFindings;
    }
    
    @Override
    public CompletableFuture<List<Finding>> reviewAsync(StaticAnalyzer.CodeSegment segment, AiReviewer.ReviewContext context) {
        return CompletableFuture.supplyAsync(() -> {
            logger.info("üîç Mock AI reviewer analyzing single segment: {} (lines {}-{})", 
                segment.filePath(), segment.startLine(), segment.endLine());
            
            List<Finding> findings = new ArrayList<>();
            
            // Generate a mock AI finding for the code segment
            findings.add(new Finding(
                "MOCK-AI-ASYNC-001",
                segment.filePath(),
                segment.startLine(),
                segment.endLine(),
                Severity.INFO,
                Dimension.QUALITY,
                "Mock AI async review finding",
                "This is a mock finding generated by async AI review",
                "Consider applying AI-suggested best practices",
                null,
                List.of("mock-ai-reviewer"),
                0.70
            ));
            
            return findings;
        });
    }
    
    @Override
    public CompletableFuture<List<Finding>> reviewBatchAsync(List<StaticAnalyzer.CodeSegment> segments, AiReviewer.ReviewContext context) {
        return CompletableFuture.supplyAsync(() -> {
            logger.info("ü§ñ Mock AI reviewer batch analyzing {} code segments for PR {}/{}#{}", 
                segments.size(), context.repository().owner(), context.repository().name(), context.pullRequest().number());
            
            List<Finding> findings = new ArrayList<>();
            
            for (StaticAnalyzer.CodeSegment segment : segments) {
                findings.add(new Finding(
                    "MOCK-AI-BATCH-" + segment.filePath().hashCode(),
                    segment.filePath(),
                    segment.startLine(),
                    segment.endLine(),
                    Severity.MINOR,
                    Dimension.MAINTAINABILITY,
                    "Mock batch AI review finding",
                    "Cross-segment analysis result",
                    "Consider refactoring for better cohesion across components",
                    null,
                    List.of("mock-ai-reviewer"),
                    0.75
                ));
            }
            
            logger.info("‚úÖ Mock AI reviewer batch found {} findings from {} segments", 
                findings.size(), segments.size());
            
            return findings;
        });
    }
    
    @Override
    public CompletableFuture<Finding> generateSummaryAsync(List<StaticAnalyzer.CodeSegment> allSegments, 
                                                         List<Finding> staticFindings, 
                                                         AiReviewer.ReviewContext context) {
        return CompletableFuture.supplyAsync(() -> {
            return new Finding(
                "MOCK-AI-SUMMARY-001",
                "SUMMARY",
                1, 1,
                Severity.INFO,
                Dimension.QUALITY,
                "Mock AI Summary Review",
                String.format("Overall analysis of %d segments and %d static findings", 
                    allSegments.size(), staticFindings.size()),
                "This is a comprehensive mock summary of the code review. " +
                "In a real implementation, this would provide high-level insights " +
                "about the overall code quality and architectural considerations.",
                null,
                List.of("mock-ai-reviewer"),
                0.80
            );
        });
    }
    
    @Override
    public ReviewerValidationResult validateConfiguration(ReviewerConfig config) {
        // Mock reviewer doesn't require any specific configuration
        return ReviewerValidationResult.success();
    }
    
    @Override
    public ReviewerStats getStats() {
        return new ReviewerStats(
            5,  // totalRequests
            4,  // successfulRequests
            1,  // failedRequests
            2500, // totalTokensUsed
            800.0, // avgResponseTimeMs
            500.0, // avgTokensPerRequest
            java.time.Instant.now().minusSeconds(30), // lastRequestTime
            null // lastError
        );
    }
    
    @Override
    public int estimateTokenUsage(StaticAnalyzer.CodeSegment segment, ReviewContext context) {
        // Simple mock estimation: ~4 chars per token + prompt overhead
        int codeTokens = segment.content().length() / 4;
        int promptTokens = 600; // Mock prompt overhead
        return codeTokens + promptTokens;
    }
    
    /**
     * Helper method to count added lines in a diff hunk.
     */
    private int countAddedLines(DiffHunk hunk) {
        if (hunk.patch() == null) {
            return 0;
        }
        
        String[] lines = hunk.patch().split("\n");
        int count = 0;
        for (String line : lines) {
            if (line.startsWith("+") && !line.startsWith("+++")) {
                count++;
            }
        }
        return count;
    }
}
